### CURRENT STAGE OF THIS DOCUMENT: Rapidly changing, highly incomplete, based on a four node configuration, though only three nodes are available at the time of this writing, likely brittle do to lots of automation based on this specific configuration.
#### Last updated: 2019.10.10, PM PDT

#### This document is a strictly guided, step-by-step implementation of a specific configuration based on the SUSE Enterprise Storage 6 Deployment Guide: https://documentation.suse.com/ses/6/single-html/ses-deployment/#book-storage-deployment
* This specific configuration is based on five nodes:
** Administrative Workstation - VM or bare-metal host
** Four OSD Nodes - bare-metal hosts
** Three Monitor Nodes - collocated with the first three OSD Nodes
** One RGW Node - collocated it the fourth OSD Node

#### Format of this document will be to create SES6 PoC installation notes here, then link https://github.com/alexarnoldy/caasp-ses-datahub/blob/master/caaspv4-installation-notes.adoc

CAUTION: All changes to the SES6 procedures will be made here. All changes to the CaaSP4v procedures will be made in the linked document. 


CAUTION: This guide can be used as a reference while deploying different configurations, but deviating from the specified design will cause unpredicable results

NOTE: Though the SES6 cluster will be used primarily to support the CaaS Platform cluster, it will be installed as a stand-alone storage cluster. This will allow it support additional services beyone the CaaS Platform cluster

.Required preparation that is not yet covered
* Establish an IP schema for the cluster. In this document, the Administrative Workstation (aka ses-admin.stable.suse.lab) is 172.16.200.130, the four OSD/Monitor/RGW nodes are 172.16.200.131-134
* Populate DNS records that are available to the cluster nodes

.Install the Administrative Workstation:

.Install the First OSD Node:
* Can be a VM, as long as it has access to the Internet and the cluster network
* 4 vCPU, 4096MB mem, 20GB qcow2 boot drive in default libvirt location
* Booting from ISO: Select "Installation" BUT DO NOT PRESS ENTER
* On "Boot Options:" line: `ifcfg=eth0=172.16.200.13/24,172.16.200.1,172.16.250.2,stable.suse.lab hostname=admin.stable.suse.lab`
** Format of ifcfg=eth0 is <node IP address/cidr mask>,<default gateway>,<primary DNS server>,<search domain>
* Press Enter

IMPORTANT: Use the both the SLES 15 SP1 and SUSE Enterprise Storage 6 subscription keys to register all SES nodes, including the Administrative Workstation

* Use the SLES 15 SP1 subscription key first, as with a normal SUSE Linux Enterprise Server installation
* Enable the SUSE Enterprise Storage 6 repository
** This should also enable the Basesystem Module 
* Provide the SUSE Enterprise Storage 6 subscription key
* Select the "Text Mode" System Role 

IMPORTANT: Use great care in selecting the system (boot) drive to ensure an OSD drive or write-caching drive isn't inadvertently used as the system drive. If this occurs, the node will need to be re-installed. If this error is propogated into the AutoYaST file that is used to install the remaining OSD nodes, all affect nodes will need to be re-installed.

* Select any partitioning scheme, but it is not recommended to enable LVM and it is recommended to deselect "Enlarge to RAM Size for Suspend"

IMPORTANT: LVM is not needed on OSD Nodes and is incompatible with OSD drives. For that reason it is often safer to avoid LVM on OSD Nodes

* A separate Home Partition is not needed on the OSD Nodes but can be configured, if desired
* Create New User:
** User's Full Name and Username: sles

IMPORTANT: It is recommended to use a secure password that will work with all elements of the PoC environment. Therefore a password should be selected that includes at least one upper case and one lower case letter, one number and at least one of the following three special characters: ! # $

* Select "Use this password for system administrator", but do not select Automatic Login 
* On the final "Installation Settings" screen:
** Under Security, disable the Firewall
* Install


when you get to accepting salt keys, if all the host names aren't showing up as fully qualified, we need to look at it and remediate, as this will break stuff after the fact. 

also, there is a bug in SLES15SP1 where if you create a bond and assign the fqdn hostname to the interface that it will lose it after the first reboot. you have to go back into yast2 and re-declare it, and then it sticks.






// vim: set syntax=asciidoc:
